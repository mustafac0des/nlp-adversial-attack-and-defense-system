{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf95144b",
   "metadata": {},
   "source": [
    "Adversial Attack Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "878f0256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from datasets) (3.24.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from datasets) (2.4.2)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from datasets) (23.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from datasets) (0.4.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from datasets) (3.0.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from datasets) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from datasets) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from datasets) (4.67.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from datasets) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.19 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from datasets) (0.70.18)\n",
      "Requirement already satisfied: fsspec<=2025.10.0,>=2023.1.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2025.10.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from datasets) (1.4.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\mustafa amanullah\\appdata\\roaming\\python\\python314\\site-packages (from datasets) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from datasets) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (3.13.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1.0.0->datasets) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1.0.0->datasets) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1.0.0->datasets) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.2.0)\n",
      "Requirement already satisfied: shellingham in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (0.23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from requests>=2.32.2->datasets) (2.6.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\mustafa amanullah\\appdata\\roaming\\python\\python314\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mustafa amanullah\\appdata\\roaming\\python\\python314\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas->datasets) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mustafa amanullah\\appdata\\roaming\\python\\python314\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: typer>=0.23.1 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (0.23.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from typer>=0.23.1->typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (8.3.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from typer>=0.23.1->typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (14.3.2)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from typer>=0.23.1->typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from rich>=10.11.0->typer>=0.23.1->typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mustafa amanullah\\appdata\\roaming\\python\\python314\\site-packages (from rich>=10.11.0->typer>=0.23.1->typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.23.1->typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: numpy>=2.3.3 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\mustafa amanullah\\appdata\\roaming\\python\\python314\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mustafa amanullah\\appdata\\roaming\\python\\python314\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers) (2.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mustafa amanullah\\appdata\\roaming\\python\\python314\\site-packages (from transformers) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers) (0.23.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers) (4.67.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (3.24.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (0.28.1)\n",
      "Requirement already satisfied: shellingham in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers) (0.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mustafa amanullah\\appdata\\roaming\\python\\python314\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: typer>=0.23.1 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from typer-slim->transformers) (0.23.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from typer>=0.23.1->typer-slim->transformers) (8.3.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from typer>=0.23.1->typer-slim->transformers) (14.3.2)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from typer>=0.23.1->typer-slim->transformers) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from rich>=10.11.0->typer>=0.23.1->typer-slim->transformers) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mustafa amanullah\\appdata\\roaming\\python\\python314\\site-packages (from rich>=10.11.0->typer>=0.23.1->typer-slim->transformers) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.23.1->typer-slim->transformers) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from torch) (3.24.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from torch) (2025.10.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from torch) (82.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (5.1.0)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers[torch]) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers[torch]) (2.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mustafa amanullah\\appdata\\roaming\\python\\python314\\site-packages (from transformers[torch]) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers[torch]) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers[torch]) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers[torch]) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers[torch]) (0.23.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers[torch]) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers[torch]) (4.67.3)\n",
      "Requirement already satisfied: torch>=2.4 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers[torch]) (2.10.0)\n",
      "Requirement already satisfied: accelerate>=1.1.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from transformers[torch]) (1.12.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers[torch]) (3.24.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers[torch]) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers[torch]) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers[torch]) (0.28.1)\n",
      "Requirement already satisfied: shellingham in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers[torch]) (1.5.4)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from huggingface-hub<2.0,>=1.3.0->transformers[torch]) (4.15.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers[torch]) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers[torch]) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers[torch]) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers[torch]) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers[torch]) (0.16.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\mustafa amanullah\\appdata\\roaming\\python\\python314\\site-packages (from accelerate>=1.1.0->transformers[torch]) (7.2.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from torch>=2.4->transformers[torch]) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from torch>=2.4->transformers[torch]) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from torch>=2.4->transformers[torch]) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from torch>=2.4->transformers[torch]) (82.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from sympy>=1.13.3->torch>=2.4->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mustafa amanullah\\appdata\\roaming\\python\\python314\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from jinja2->torch>=2.4->transformers[torch]) (3.0.3)\n",
      "Requirement already satisfied: typer>=0.23.1 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from typer-slim->transformers[torch]) (0.23.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from typer>=0.23.1->typer-slim->transformers[torch]) (8.3.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from typer>=0.23.1->typer-slim->transformers[torch]) (14.3.2)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from typer>=0.23.1->typer-slim->transformers[torch]) (0.0.4)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from rich>=10.11.0->typer>=0.23.1->typer-slim->transformers[torch]) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\mustafa amanullah\\appdata\\roaming\\python\\python314\\site-packages (from rich>=10.11.0->typer>=0.23.1->typer-slim->transformers[torch]) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\mustafa amanullah\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.23.1->typer-slim->transformers[torch]) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.3 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# installing libraries\n",
    "\n",
    "!pip install datasets\n",
    "!pip install pandas\n",
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install transformers[torch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e6dcda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch \n",
    "import re\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6cfd143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the imdb dataset\n",
    "\n",
    "dataset_movie_reviews = load_dataset(\"stanfordnlp/imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad64e557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pandas dataframe\n",
    "\n",
    "df_movie_reviews_train = pd.DataFrame(dataset_movie_reviews[\"train\"])\n",
    "df_movie_reviews_test = pd.DataFrame(dataset_movie_reviews[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c82e4613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n",
      "I of course saw the previews for this at the beginning of some other Lion's Gate extravaganza, so of course it was only the best parts and therefore looked intriguing. And it is, to a point. A young college student (Sarah)is finding riddles all over the place and is becoming obsessed with answering them, and in doing so she's unwittingly becoming involved in some game. Now that's fairly intriguing right there but unfortunately it all gets rather muddled and becomes so complicated that the viewer (like myself) will most likely become frustrated. Characters appear with little introduction and you're not really sure who they are or why Sarah knows them or is hanging out with them. All of this has something to do with this woman who tried to drown a young boy years ago and her reason for that was that it's \"all part of the design\". In reality, it's all part of the \"very sketchy script\" and when the film is over you'll find yourself feeling that you've lost about an hour and a half of your life that you want back for more productive uses of your time, like cleaning the bathroom, for instance. 4 out of 10.\n"
     ]
    }
   ],
   "source": [
    "# exploring the datasets\n",
    "\n",
    "print(df_movie_reviews_train[\"text\"][0] + \"\\n\" + df_movie_reviews_test[\"text\"][25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690579cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data cleaning \n",
    "\n",
    "def clean_text_movie_reviews(text, n=100):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    text = html.unescape(text)\n",
    "    text = re.sub(r\"<[^>]*>\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    text = re.sub(r\"\\\\[nrt]\", \" \", text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "df_movie_reviews_train[\"text\"] = df_movie_reviews_train[\"text\"].apply(clean_text_movie_reviews)\n",
    "print(df_movie_reviews_train[\"text\"][211])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34e43362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself. The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men. What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it's not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films. I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn't have much of a plot.\n",
      "too bad this movie isn't. While \"Nemesis Game\" is mildly entertaining, I found it hard to suspend my disbelief the whole length of the movie, especially the situations that Sara was putting herself into. Are we supposed to believe that: 1) this hot chick is going to go slumming unarmed around abandoned buildings and dark subway tunnels in the middle of the night just to solve some riddles? 2) the protagonists are supposedly such experts that they play riddle games for fun, but don't put the whole \"I Never Sinned\" riddle together until the very end...and then...and then...get this...she has to do the whole mirror thing to finally put the pieces together?? I know it was the filmmaker's device to show the audience what was going on, but do they really think we're that stupid? 3) when Vern and Sara go to the Chez M to question the blonde, there is not ONE topless chick in the whole building. Nada. C'mon. I know it's Canada, but I would expect more from a country that gave us Shannon Tweed. And anyone else notice that when Vern was surfing the Web and found that riddlezone site, that when he moused over the link the cursor stayed an arrow, and didn't turn into a little hand (LIKE ALL CURSORS DO WHEN YOU CLICK ON A HYPERLINK)?!? I mean, if you're gonna have the internet play such a prominent role in your movie, at least get the little things right. Geez.\n"
     ]
    }
   ],
   "source": [
    "# re-exploring the datasets\n",
    "\n",
    "print(df_train[\"text\"][0] + \"\\n\" + df_test[\"text\"][24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d987614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    }
   ],
   "source": [
    "# encode the \"text\" data for train and test datasets\n",
    "\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "train_encodings = tokenizer(df_train[\"text\"].tolist(), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(df_test[\"text\"].tolist(), truncation=True, padding=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e5e3ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0, 1}, {0, 1})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "\n",
    "train_labels = df_train[\"label\"].tolist()\n",
    "test_labels = df_test[\"label\"].tolist()\n",
    "\n",
    "set(train_labels), set(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2dd3d153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset class for pytorch\n",
    "\n",
    "import torch\n",
    "\n",
    "class IMDBDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "train_dataset = IMDBDataset(train_encodings, train_labels)\n",
    "test_dataset = IMDBDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29bc0958",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|██████████| 199/199 [00:01<00:00, 151.77it/s, Materializing param=bert.pooler.dense.weight]                               \n",
      "\u001b[1mBertForSequenceClassification LOAD REPORT\u001b[0m from: bert-base-uncased\n",
      "Key                                        | Status     | \n",
      "-------------------------------------------+------------+-\n",
      "cls.predictions.transform.dense.bias       | UNEXPECTED | \n",
      "cls.seq_relationship.weight                | UNEXPECTED | \n",
      "cls.predictions.transform.dense.weight     | UNEXPECTED | \n",
      "cls.predictions.bias                       | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.bias   | UNEXPECTED | \n",
      "cls.predictions.transform.LayerNorm.weight | UNEXPECTED | \n",
      "cls.seq_relationship.bias                  | UNEXPECTED | \n",
      "classifier.weight                          | MISSING    | \n",
      "classifier.bias                            | MISSING    | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
      "- MISSING\u001b[3m\t:those params were newly initialized because missing from the checkpoint. Consider training on your downstream task.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# load the model \n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36aea4ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`logging_dir` is deprecated and will be removed in v5.2. Please set `TENSORBOARD_LOGGING_DIR` instead.\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16, \n",
    "    per_device_eval_batch_size=64,\n",
    "    eval_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04756688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mustafa amanullah\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:775: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  super().__init__(loader)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='4689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   3/4689 01:55 < 150:21:18, 0.01 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# training the model \n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1208e205",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mustafa amanullah\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 120000\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label'],\n",
      "        num_rows: 7600\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# pull the ag news dataset\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"fancyzhx/ag_news\")\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ba028ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pandas dataframe\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "df_news = pd.DataFrame(dataset[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22e5216c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group to Propose New High-Speed Wireless Format A group of technology companiesincluding Texas Instruments Inc. (TXN.N), STMicroelectronics(STM.PA) and Broadcom Corp. (BRCM.O), on Thursday said theywill propose a new wireless networking standard up to 10 timesthe speed of the current generation.\n"
     ]
    }
   ],
   "source": [
    "print(df_news[\"text\"][79])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "50cdaa85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mustafa amanullah\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\huggingface_hub\\file_download.py:130: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\mustafa amanullah\\.cache\\huggingface\\hub\\datasets--anitamaxvim--jigsaw-toxic-comments. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|██████████| 159571/159571 [00:01<00:00, 125376.77 examples/s]\n",
      "Generating test split: 100%|██████████| 63978/63978 [00:00<00:00, 236257.10 examples/s]\n",
      "Generating balanced_train split: 100%|██████████| 54083/54083 [00:00<00:00, 347415.67 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'],\n",
      "        num_rows: 159571\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'],\n",
      "        num_rows: 63978\n",
      "    })\n",
      "    balanced_train: Dataset({\n",
      "        features: ['comment_text', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'],\n",
      "        num_rows: 54083\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# pull toxic comments dataset \n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"anitamaxvim/jigsaw-toxic-comments\")\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a80e944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ds = pd.DataFrame(ds[\"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83c59d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Your vandalism to the Matt Shirvington article...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sorry if the word 'nonsense' was offensive to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>alignment on this subject and which are contra...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic  severe_toxic  \\\n",
       "0  Explanation\\nWhy the edits made under my usern...      0             0   \n",
       "1  D'aww! He matches this background colour I'm s...      0             0   \n",
       "2  Hey man, I'm really not trying to edit war. It...      0             0   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0             0   \n",
       "4  You, sir, are my hero. Any chance you remember...      0             0   \n",
       "5  \"\\n\\nCongratulations from me as well, use the ...      0             0   \n",
       "6       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1             1   \n",
       "7  Your vandalism to the Matt Shirvington article...      0             0   \n",
       "8  Sorry if the word 'nonsense' was offensive to ...      0             0   \n",
       "9  alignment on this subject and which are contra...      0             0   \n",
       "\n",
       "   obscene  threat  insult  identity_hate  \n",
       "0        0       0       0              0  \n",
       "1        0       0       0              0  \n",
       "2        0       0       0              0  \n",
       "3        0       0       0              0  \n",
       "4        0       0       0              0  \n",
       "5        0       0       0              0  \n",
       "6        1       0       1              0  \n",
       "7        0       0       0              0  \n",
       "8        0       0       0              0  \n",
       "9        0       0       0              0  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "47acd0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.isna().sum()\n",
    "ds.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1f861f84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Welcome! Hello, , and welcome to Wikipedia! Thank you for your contributions. I hope you like the place and decide to stay. Here are some pages that you might find helpful: The five pillars of Wikipedia How to edit a page Help pages', 82), ('Thank you for experimenting with Wikipedia. Your test worked, and it has been reverted or removed. Please use the sandbox for any other tests you may want to do. Take a look at the welcome page to learn more about contributing to our', 43), ('\"Welcome! Hello, , and welcome to Wikipedia! Thank you for your contributions. I hope you like the place and decide to stay. Here are some pages that you might find helpful: The five pillars of Wikipedia Tutorial How to edit a page How', 41), ('\" Welcome! Hello, , and welcome to Wikipedia! Thank you for your contributions. I hope you like the place and decide to stay. Here are some pages that you might find helpful: The five pillars of Wikipedia How to edit a page Help', 37), ('\"Thank you for experimenting with Wikipedia. Your test worked, and it has been reverted or removed. Please use the sandbox for any other tests you may want to do. Take a look at the welcome page to learn more about contributing to our', 36), ('\" {| style=\"\"background-color:#F5FFFA; padding:0;\"\" cellpadding=\"\"0\"\" |style=\"\"border:1px solid #084080; background-color:#F5FFFA; vertical-align:top; color:#000000;\"\"| Hello, ! Welcome to Wikipedia! Thank you for your contributions to this free encyclopedia. If you decide that you need help, check out Getting Help below, ask me on , or place', 32), ('Welcome! Hello, , and welcome to Wikipedia! Thank you for your contributions. I hope you like the place and decide to stay. Here are a few good links for newcomers: The five pillars of Wikipedia How to edit a page Help pages Tutorial', 30), ('\" Thank you for experimenting with Wikipedia. Your test worked, and it has been reverted or removed. Please use the sandbox for any other tests you may want to do. Take a look at the welcome page to learn more about contributing to', 27), ('Welcome! Hello, , and welcome to Wikipedia! Thank you for your contributions. I hope you like the place and decide to stay. Here are some pages that you might find helpful: The five pillars of Wikipedia Tutorial How to edit a page How', 27), ('\" Welcome Hello and welcome to Wikipedia! We appreciate encyclopedic contributions, but some of your recent edits do not conform to our policies. For more information on this, see Wikipedia\\'s policies on vandalism and limits on acceptable additions. If you\\'d like to experiment', 24)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "texts = ds[\"comment_text\"].dropna().astype(str)\n",
    "\n",
    "first_20_segments = []\n",
    "\n",
    "for text in texts:\n",
    "    first_20 = \" \".join(text.split()[:43])\n",
    "    first_20_segments.append(first_20)\n",
    "\n",
    "counts = Counter(first_20_segments)\n",
    "\n",
    "print(counts.most_common(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "73b86eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm also a sock puppet of this account...SUPRISE!! -sincerely, The man that will track you down from the Internet and kill you\n",
      "All the sources needed are provided, all you need to do is read the article...but I guess you can't read. Once again you prove you are not even reading the article. Every edit is backed up with the source it came from. I am NOT going to provide you with any details, because you are merely a civillain editor and not a Wikipedia staff member. You have all the info you need within the PIRA text edits. If a actual Wikipedia staff member wants more specifics I will be happy to provide them Look, you are obviously a Anti-IRA hack who is making things up to support your bias. I am neither pro not anti IRA. I have no bias, I merely report facts. I will be checking this page daily, and will continue to submit my PIRA entry because it is by far the most accurate and factually supported. We can do this several times a day if you wish, or you can accept the fact that mine is the superior version and just deal with it. It's up to you, but I will re-edit on a regular basis. Or we can agree to incorporate your fatcxs and mine into one article. But the three areas. The number of Loyalists killed from 1974 to 1998 The number of IRA victims as broken down by both Janes Intelligence online and the CFR. and the IRA/RussianMafia connection which has been documented in multiple books and newspaper sources. These three things are verifiable and will remain.\n",
      "Are you fucker mother fucker have nothing to do but block University computers. Go and suck cocks\n",
      "It's from one of the many books on various bands... I thought it was from Cult Rockers, but I just checked and Supertramp isn't in there. I will seek out a source for this quote. -\n",
      "HELLO You disgrace to humanity. Stop wasting valuable Internet resources (your killing the fucking planet) and throw out your PC. PS it's like 3am what the fark kinda life do you have on Wikipedia 24/7. A VERY SAD AND LONELY ONE LOL. Life's too short find something better to do\n",
      "I've explained my reasoning for this block at User_talk:Gwen_Gale#User:Professional_Assassin.\n",
      "When an article is created about that album then a disambiguation page will be created.\n",
      "That would be pretty odd for those declassified documents to mention a movie that was created after the events for which both the movie and the documents do related about. The declassified documents were not synthesized for the movie, unless you want to prove a conspiracy on the synthesis (very odd). It is perfectly valid to use the documents to relate to the same historical events to further verify the what happened, but the use of primary source in such a was is not ideal for wikipedia. Since it is not ideal, that is why I left it here on the talk page if someone wants to research it more to find ideal references. —\n",
      "Your retarded bot Your bot is entirely automated, that is wrong. You should not leave an unattented script just running through the site like that, it is idiotic of you to suppose that your scripting abilities are so perfect that they will only ever make proper edits. Banning me doesn't help anything, dipshit, since I have as many IPs as I want.\n",
      "two reversions on Hezbollah Could you explain on the talk page why you have reverted my edit twice?\n",
      "DISLIKE RACISM AND I CAN SEE THAT YOU HAS PROBLEMS WITH PEOPLE WHO SPEAKS SPANISH. YOU ARE AN ANTISEMITE TOO.\n",
      "The name\"Yuen Lou\"looks to be just a variation of\"Yuen Lo\"\", the name Jackie used under his sifu at the opera school.\n",
      "2010]] [[User talk:Wikireader41/Archive4|Archive 5-Mar 15\n",
      "I realize now that the article doesn't quite say what I thought it said. If anyone can find a citation stating that there exists a proper subfield of isomorphic to itself, I would be very interested in seeing it (and we could reinclude the clause with the citation).\n",
      "I didn't cherry-pick anything, these are the official and only facts:\"While essentially every CNN program was down double-digits, 9pmET, which is home to “Piers Morgan Tonight,” and 7pmET, which is home to “Erin Burnett OutFront,” each had their worst performance in the demo in 20 years.\"http://www.mediabistro.com/tvnewser/may-2012-ratings-cnn-hits-20-year-low_b130250\n",
      "Direct/Indirect relation Is it correct to say that (technically) if a 45 degree shot (by elevation) reaches the longest distance, then a 30 degree (45-15) will reach the same distance as a 60 degree (45+15) shot? If so, could the lower-than-45 shot be considered direct fire, and the higher-than-45 shot considered indirect fire? If so, I think this is a great explanation (or one way of viewing things).\n",
      "Title section revert Hi, I was at the office earlier and I hadn't noticed your warning before restoring the title of the section. I'm sorry for that. Of course I won't do such a revert again. Just to clarify, I've opened a new section to indeed alert some contributors that they were behaving in a way in line with the examples of ownership behaviour as described here. In return the title of the section has been twisted to something unrelated and one of my message has been erased. It is the first time I see people editing other's signed contributions in a talk page. This just looks crazy to me.\n",
      "Noel, you are an expert. Please convince Whig history fans (or the lazy minds) about how Bonnie Prince Charlie did not want to dissolve the Union, that the United Kingdom began with the Stuarts as opposed to the Hanoverians. Tell them how the Whigs rewrote history to blame everything on the Stuarts, whom are credited as ultimate failures with no positive contributions to the foundations of Great Britain in their Stewart and Tudor blood. The Sovereign's will is the Realm, or else it is not a kingdom. The British might as well be living in a republic, at least if the Parliamentarians had their way. Even the Hanoverian heirs recognise that the Stuarts founded the UK. Please debate that here & thanks.\n",
      "Warning. Earth, I'd like to leave you access to your talk page so that in perhaps six months you can convince us that we should try again - if you're so inclined. But you're making it hard. If you continue these abusive comments, I will revoke your talk page access.\n",
      "should be jaeger regardless of what other people have\"decided\"\", erens name should be jaeger. its like calling light (from death note) raito. at least in the anime, the people dubbing take care to correctly pronounce the foreing names (ie, all of them, except mikasa) jaeger means hunter, a german word. guess what eren does in the series?\n"
     ]
    }
   ],
   "source": [
    "import html, re\n",
    "\n",
    "def clean_text_general(text, n=100):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # 1. Unescape HTML entities\n",
    "    text = html.unescape(text)\n",
    "    text = html.unescape(text)  # double-unescape if needed\n",
    "    \n",
    "    # 2. Remove HTML tags\n",
    "    text = re.sub(r\"<[^>]*>\", \" \", text)\n",
    "    \n",
    "    # 3. Remove stray backslashes\n",
    "    text = text.replace(\"\\\\\", \"\")\n",
    "    text = text.replace(\"\\\" \", \"\")\n",
    "    text = text.replace(\" \\\"\", \"\")\n",
    "    \n",
    "    # 4. Collapse multiple spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    \n",
    "    # 5. Remove source prefix within first n characters\n",
    "    prefix = text[:n]\n",
    "    rest = text[n:]\n",
    "    \n",
    "    # Match: \"(anything) same_text [-—:]\"\n",
    "    prefix_clean = re.sub(r\"\\((.*?)\\)\\s*\\1\\s*[-—:]\\s*\", \"\", prefix, flags=re.I)\n",
    "    \n",
    "    text = (prefix_clean + rest).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "ds[\"comment_text\"] = ds[\"comment_text\"].apply(clean_text_general)\n",
    "\n",
    "for i in range(20):\n",
    "    print(ds.comment_text[i+600])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
